{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>  Algoritmo Evolución Diferencial  <<<<<<<\n",
      "\n",
      "------ Datos de Entrada ------\n",
      "\n",
      "database=Iris\n",
      "Poblacion = 100\n",
      "d=4\n",
      "K=3\n",
      "rand:  1\n",
      "\n",
      "------ centroides: ------\n",
      "\n",
      "[16 62]\n",
      "\n",
      "------ Cromosoma: ------\n",
      "\n",
      "[0.53883106 0.55282198 0.48148148 0.41666667 0.85365854 0.82352941\n",
      " 0.11111111 0.45833333 0.12195122 0.05882353] \n",
      "\n",
      "\n",
      "------ umbrales activos: ------\n",
      "\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#///////// Implementación de dos métodos de agrupamiento usando evolución diferencial /////////\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from numpy.linalg import *\n",
    "import pylab\n",
    "from sklearn import datasets\n",
    "from math import *\n",
    "\n",
    "print('>>>>>  Algoritmo Evolución Diferencial  <<<<<<<')\n",
    "print('\\n------ Datos de Entrada ------\\n')\n",
    "print('database=Iris')\n",
    "print('Poblacion = 100')\n",
    "print('d=4')\n",
    "print('K=2')\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#---------------VERIABLES----------------\n",
    "\n",
    "iris = datasets.load_iris() #se carga el conjunto de datos de IRIS\n",
    "\n",
    "#---se seleccionan los primeros 100 datos\n",
    "data = iris.data[:100]\n",
    "target = iris.target[:100]\n",
    "data = (data - data.min(axis=0))/(data.max(axis=0)-data.min(axis=0))\n",
    "N = len(data)\n",
    "n = len(data[0]) #longitud del individuo\n",
    "K = 2 #numero de clusters\n",
    "chrom = []#vector que guarda los K cromosomas de (K + K*d)\n",
    "\n",
    "#--------------------FUNCIONES------------------\n",
    "def dist_to_centroids(CHROM, IND, clusters_activos):\n",
    "    distancias = np.array([])\n",
    "    \n",
    "    #print('IND: ', IND)\n",
    "    #print('umbral: ',UMBRALES)\n",
    "    \n",
    "    \n",
    "    #print('clusters activos: ', clusters_activos)\n",
    "    for activo in clusters_activos:         \n",
    "        cluster = []\n",
    "        for n in range(K + activo*len(IND), K + activo*len(IND) + len(IND)):\n",
    "            cluster.append(CHROM[n])\n",
    "        #print('cluster: ', cluster)\n",
    "        acum = 0.0\n",
    "        for p in range(len(IND)):#se recorre cada elemento del individuo\n",
    "            acum += pow(IND[p] - cluster[p], 2)\n",
    "        #print('acum: ',acum)\n",
    "        distancias = np.append(distancias, sqrt(acum))\n",
    "    \n",
    "    return distancias\n",
    "\n",
    "#funcion para encontrar los clusters activos del cromosoma\n",
    "def get_active_clusters(CHROM):\n",
    "    active = np.zeros(K) # se inicializan los valores de los umbrales en ceros(inactivos)\n",
    "    \n",
    "    #se recorren las primeras K posiciones del cromosoma (umbrales de activacion)\n",
    "    inactive = []#almacena los clusters inactivos\n",
    "    for umbral in range(K):\n",
    "        if CHROM[umbral] > 0.5:\n",
    "            active[umbral] = 1\n",
    "        else:\n",
    "            inactive.append(umbral)\n",
    "\n",
    "    #se valida que al menos dos umbrales esten activos\n",
    "    if sum(active) < 2.0:\n",
    "        while(sum(active) < 2.0):            \n",
    "            r = np.random.randint(len(inactive)) \n",
    "            i = inactive[r]\n",
    "            CHROM[i] = np.random.randint(500,1000)*.001\n",
    "            #print('inactive:', inactive, '  irand:', i)\n",
    "            active[ i ] = 1\n",
    "            inactive.pop(r)\n",
    "    \n",
    "    return [i for i,x in enumerate(active) if x==1.0]\n",
    "\n",
    "\n",
    "def get_chromosome(UMBRALES, CENTROIDS):\n",
    "    #se unen los umbrales con los centroides\n",
    "    for centroid in CENTROIDS: UMBRALES = np.concatenate((UMBRALES, data_training[centroid]))\n",
    "    \n",
    "    return UMBRALES\n",
    "    \n",
    "        \n",
    "    \n",
    "print ('rand: ', np.random.randint(3))\n",
    "\n",
    "#funcion objetivo 1\n",
    "#funcion objetivo 2\n",
    "\n",
    "#se seleccionan 100 indices desordenados entre [0,100]\n",
    "idx = np.random.permutation(N)\n",
    "data_training = data[idx[:int(N*.8)]]\n",
    "target_training = target[idx[:int(N*.8)]]\n",
    "\n",
    "\n",
    "#se seleccionan los K centroides de manera aleatoria\n",
    "centroids = np.random.permutation(int(N*.8))[:K]\n",
    "print('\\n------ centroides: ------\\n')\n",
    "print(centroids)\n",
    "\n",
    "\n",
    "#se generan los valores Ti,j (umbrales de activacion del centroide)\n",
    "chrom = np.random.rand(K)\n",
    "#se inicializan el cromosoma de dimension Kmax + Kmax*d\n",
    "chrom = get_chromosome(chrom, centroids)\n",
    "    \n",
    "print('\\n------ Cromosoma: ------\\n')\n",
    "print(chrom,'\\n')\n",
    "print('\\n------ umbrales activos: ------\\n')\n",
    "clusters_activos = get_active_clusters(chrom)\n",
    "print(clusters_activos)\n",
    "\n",
    "#dis = distancia(data_training[0], umbrales)\n",
    "#print(dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit:  0.27162139339015445\n",
      "fit:  0.2679601543593448\n",
      "fit:  0.2552421731584942\n",
      "fit:  0.25561466960040663\n",
      "fit:  0.2464820575515423\n",
      "fit:  0.23500130218309506\n",
      "fit:  0.2525347262976783\n",
      "fit:  0.23809562200124015\n",
      "fit:  0.21391915935504724\n",
      "fit:  0.24394707735155896\n",
      "fit:  0.26085131162597186\n",
      "fit:  0.2757836851055452\n",
      "fit:  0.21534905062285653\n",
      "fit:  0.22264538872951115\n",
      "fit:  0.24683336497348354\n",
      "fit:  0.25933192945919215\n",
      "fit:  0.25476170171050017\n",
      "fit:  0.22599416240600434\n",
      "fit:  0.2453107129534359\n",
      "fit:  0.236143694025701\n",
      "fit:  0.23981057121707444\n",
      "fit:  0.24893447945017144\n",
      "fit:  0.2515326822773542\n"
     ]
    }
   ],
   "source": [
    "#def init_clusters():\n",
    "    #ind = len(data_training) / K #cantidad de puntos por cluster\n",
    "    #for\n",
    "    \n",
    "#DB-Index\n",
    "def DB_Index(DATA, CLUSTERS):\n",
    "    \n",
    "    R = []\n",
    "    \n",
    "    for idCluster in range(K):\n",
    "        \n",
    "        S = []    \n",
    "        for cluster in CLUSTERS:\n",
    "            Nc = len(cluster)\n",
    "            #print('Cluster:',cluster)\n",
    "            acum = 0.0\n",
    "            for X in cluster:\n",
    "                #print(X[1])\n",
    "                acum += abs(X[1])*abs(X[1])\n",
    "            S.append(sqrt((1.0/Nc)*acum))\n",
    "            #print('Aqui')\n",
    "\n",
    "        d = []\n",
    "        for i in range(K):\n",
    "            if i != idCluster:\n",
    "                acum = 0.0\n",
    "                for j in range(len(data_training[0])):\n",
    "                    Ci = DATA[centroids[idCluster]]\n",
    "                    Cj = DATA[centroids[i]]\n",
    "                    acum += pow(Ci[j] - Cj[j], 2)\n",
    "                d.append(sqrt(acum))\n",
    "            else:\n",
    "                d.append([])\n",
    "        \n",
    "        #print('S:',S)\n",
    "        #print('d:',d)\n",
    "        \n",
    "        VECTOR = []\n",
    "        for i in range(K):\n",
    "            if i != idCluster:\n",
    "                VECTOR.append( (S[idCluster] + S[i]) / d[i] )\n",
    "        \n",
    "        #print('VECTOR:',VECTOR)\n",
    "        R.append(max(VECTOR))\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "    #print('\\n\\n')\n",
    "    #print('R:', R)\n",
    "    \n",
    "    return (1.0/K)*sum(R)\n",
    "\n",
    "#CS-Measure\n",
    "def CS_Measure():\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_clusters(DATA, CHROM):\n",
    "    CLUSTERS = [] #almacena los individuos de cada uno de los clusters\n",
    "    for c in range(K): CLUSTERS.append([])\n",
    "        \n",
    "    clusters_activos = get_active_clusters(CHROM)\n",
    "    #print('activos: ',clusters_activos)\n",
    "        \n",
    "    #para cada individuo calcular la distancia a todos los clusters activos\n",
    "    for IND in DATA:\n",
    "        #se obtienen las distancias de individuo actual hacia los clusters activos\n",
    "        all_dist = dist_to_centroids(CHROM, IND, clusters_activos)\n",
    "        #se obtiene el indice del cluster con la distancia mas cercana\n",
    "        best = clusters_activos[ list(all_dist).index(min(all_dist)) ]\n",
    "        #if best == 0: print('Dist:', all_dist,'  best:', best)\n",
    "        CLUSTERS[best].append([list(IND), min(all_dist)])\n",
    "    \n",
    "    return CLUSTERS\n",
    "\n",
    "def f1(DATA, CLUSTERS):\n",
    "    return 1.0/(DB_Index(DATA,CLUSTERS) + exp(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t = 0\n",
    "lb = -1.5\n",
    "ub = 2.0\n",
    "CR = 0.8\n",
    "F = 0.5\n",
    "N = len(data_training)\n",
    "u = np.zeros((N,n))\n",
    "Tmax = 50\n",
    "\n",
    "DATA_CLUSTERS = []\n",
    "\n",
    "while (t < Tmax):  \n",
    "    \n",
    "    #se generan los valores Ti,j (umbrales de activacion del centroide)\n",
    "    chrom = np.random.rand(K)\n",
    "    #se inicializan el cromosoma de dimension Kmax + Kmax*d\n",
    "    chrom = get_chromosome(chrom, centroids)\n",
    "    \n",
    "    DATA_CLUSTERS = get_clusters(data_training, chrom)\n",
    "    \n",
    "    for i in range(N):\n",
    "        [r1, r2, r3] = np.random.permutation(N)[:3]\n",
    "        irand = np.random.randint(n)\n",
    "        for j in range(n):\n",
    "            if np.random.random() < CR or j == irand:\n",
    "                u[i,j] = data_training[r3,j] + F * (data_training[r1,j] - data_training[r2,j])\n",
    "                if u[i,j] < lb or u[i,j] > ub:\n",
    "                    u[i,j] = (data_training[r1,j] + data_training[r2,j] + data_training[r3,j])/3.0\n",
    "            else:\n",
    "                u[i,j] = data_training[i,j]\n",
    "    \n",
    "    DATA_CLUSTERS2 = get_clusters(u, chrom)\n",
    "    \n",
    "    #print('CLUSTERS:\\n', (DATA_CLUSTERS[1][0]))\n",
    "    #print('CLUSTERS:\\n', (DATA_CLUSTERS2[1][0]))\n",
    "    \n",
    "    f1x = f1(data_training, DATA_CLUSTERS)\n",
    "    #print('DB: ',f1x)\n",
    "    f1u = f1(u, DATA_CLUSTERS2)\n",
    "    #print('DB2: ',f1u)\n",
    "    \n",
    "    #print('f1x:',f1x, '  f1u:',f1u)\n",
    "    \n",
    "    if(f1u > f1x):\n",
    "        data_training = u.copy()\n",
    "        print('fit: ', f1u)\n",
    "    else:\n",
    "        #se seleccionan los K centroides de manera aleatoria\n",
    "        centroids = np.random.permutation(int(N*.8))[:K]\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    #break\n",
    "    t+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
