{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (100 puntos) Implementación de dos métodos de agrupamiento usando evolución diferencial\n",
    "\n",
    "Lea el artículo \"Automatic Clustering Using an Improved Differential Evolution Algorithm\"proporcionado en Slack. Implemente DB Index y CS Measure en la Evolución Diferencial vista eimplementada en clase.Usando ambas medidas implementadas use los primeras 100 datos del conjunto de prueba \"Iris\"para agruparlos en dos conjuntos de prueba. \n",
    "\n",
    "Asegúrese que los datos de entrada están barajeadosaleatoriamente. Contabilice el número de datos mal agrupados. Ejecute 30 veces su algoritmo concada función objetivo y presente las estadísticas de los datos mal agrupados: media, mediana,desviación estándar. Haga una discusión de los resultados y también disculta el métodoimplementado para contabilizar los datos mal agrupados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El estudiante deberá entregar una notebook de python con los siguiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(100 puntos)* RBFNN (dos clases, i.e., una neurona de salida)\n",
    "\n",
    "El estudiante deberá implementar una RBFNN  que pueda reconocer la planta del iris (ver http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). Para esta entrega se requiere que pueda reconocer dos clases.\n",
    "\n",
    "El programa deberá ser capaz de interpretarse bajo Python versión 2.7 y, de ser necesario, podría requerirse al autor que demuestre el uso del programa personalmente al instructor. El código fuente deberá estar debidamente documentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[20 45 23 92 67 31 50 27 59 76 29  5 70 83  3 86 36  4 46 60 58 97 51 78\n",
      " 13 68 53 82 91 96 41 87 84 12 65 40 99 85 71 95 22 34 89 52 79 47 94 57\n",
      " 43 73 42 90 16 66  6 49 21 14  2 18 48 39 26 98 38 17 74 15 69 64 62 10\n",
      " 19 44 93 28 77 88  8 54 33 11 55  7 37 30 63 80 56 61 32 72 81  0 25  9\n",
      " 35 24  1 75]\n",
      "\n",
      "training: \n",
      " [[5.4 3.4 1.7 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.5 2.8 4.6 1.5]]\n",
      "\n",
      "testing: \n",
      " [[5.4 3.4 1.7 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.5 2.8 4.6 1.5]]\n"
     ]
    }
   ],
   "source": [
    "# Algunas bibliotecas que ocuparemos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from numpy.linalg import *\n",
    "import pylab\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data[:100]\n",
    "target = iris.target[:100]\n",
    "\n",
    "P =len(data)\n",
    "\n",
    "print(P)\n",
    "\n",
    "\n",
    "idx = np.random.permutation(P)\n",
    "print(idx)\n",
    "data_training = data[idx[:int(P*.8)]]\n",
    "target_training = target[idx[:int(P*.8)]]\n",
    "\n",
    "data_testing = data[idx[int(P*.8):]]\n",
    "print('\\ntraining: \\n', data_training)\n",
    "print('\\ntesting: \\n',data_testing)\n",
    "\n",
    "target_testing = target[idx[int(P*.8):]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (50 puntos) Validación RBF (dos clases)\n",
    "\n",
    "Realice lo siguiente para validar su RBFNN\n",
    "\n",
    "#### Conjunto de Validación y conjunto de prueba\n",
    "\n",
    "Divida aleatoriamente el total de los patrones  en dos grupos. Use el primero el primero para entrenar RBFNN, mientras que el segundo se ocupará para validarla (i.e., patrones que no hayan sido vistos por el clasificador). Se recomienda que el estudiante asigne un 75\\% del total para entrenamiento y 25\\% para validación. \n",
    "\n",
    "#### Estadísticas\n",
    "\n",
    "Al tener componentes aleatorios, la RBF debe validarse estadísticamente. Para esto, ejecute al menos 30 veces la implementación desarrollada y utilizando el conjunto de validación obtenga las siguientes métricas para cada archivo de datos:\n",
    "\n",
    "- **MSE**: Usualmente se usa el error cuadrático medio para indicar el comportamiento de la red. Se prefieren valores cercanos a cero en esta medida de desempeño.\n",
    "- **Exactitud**: En un problema de clasificación binaria, donde 0 indica no pertence y 1 si pertenece, cada uno de los patrones probados pueden ser correctos (verdadero positivo, o verdadero negativo), o inconrrectos (falso positivo o falso negativo), donde: \n",
    "    1. verdadero positivo (VP), hace referencia a que se clasificó correctamente al patrón, donde perteneciendo éste a la clase, el resultado fue verdadero (1). \n",
    "    2. verdadero negativo (VN), al igual que en el caso anterior, los verdaderos negativos son aquellos patrones que no perteneciendo a la clase, el clasifidor los clasifica correctamente (0) \n",
    "    3. falsos positivos (FP), hace referencia a aquellos patrones que  perteneciendo a una determinada clasificación (1), se le clasifica como si éstos no perteneciesen (0). \n",
    "    4. falsos negativos (FN), serían los casos contrarios, i.e., los patrones que no pertenecen a la clasificación (0), se les clasifica como que  pertenecen (1).\n",
    "    \n",
    "La exactitud entonces, la mediremos como la relación siguiente (VP+FP)/(VP+VN+FP+FN). En otras palabras, acumularemos en un contador todos aquellos patrones que fueron correctamente clasificados y lo dividiremos entre el total de patrones evaluados. Evidentemente, aquel clasificador que no tenga ningún FP o FN, dará como resultado 1 (que es el caso deseable). En caso contrario dará un valor menor a 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (20 puntos extra) Exactitud RBFF dos clases > 0.9\n",
    "\n",
    "El estudiante obtendrá 20 puntos extra si la exactitud de la RBFNN es superior a 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(100 puntos)* RBFNN (múltiples clases, i.e., más de dos neuronas de salida)\n",
    "\n",
    "\n",
    "El estudiante deberá implementar una RBFNN  que pueda reconocer la planta del iris (ver http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). La implementación debera de poder identificar instancias de las tres clases (i.e., 3 neuronas en la capa de salida). \n",
    "\n",
    "El programa deberá ser capaz de interpretarse bajo Python versión 2.7 y, de ser necesario, podría requerirse al autor que demuestre el uso del programa personalmente al instructor. El código fuente deberá estar debidamente documentado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (50 puntos) Validación RBF (múltiples clases)\n",
    "\n",
    "Realice lo siguiente para validar su RBFNN\n",
    "\n",
    "#### Conjunto de Validación y conjunto de prueba\n",
    "\n",
    "Divida aleatoriamente el total de los patrones  en dos grupos. Use el primero el primero para entrenar RBFNN, mientras que el segundo se ocupará para validarla (i.e., patrones que no hayan sido vistos por el clasificador). Se recomienda que el estudiante asigne un 75\\% del total para entrenamiento y 25\\% para validación. \n",
    "\n",
    "### Estadísticas\n",
    "\n",
    "Al tener componentes alesatorios, la RBF debe validarse estadísticamente. Para esto, ejecute al menos 30 veces la implementación desarrollada y utilizando el conjunto de validación obtenga las siguientes métricas para cada archivo de datos:\n",
    "\n",
    "- **MSE**: Usualmente se usa el error cuadrático medio para indicar el comportamiento de la red. Se prefieren valores cercanos a cero en esta medida de desempeño.\n",
    "- **Exactitud**: En un problema de clasificación binaria, donde 0 indica no pertence y 1 si pertenece, cada uno de los patrones probados pueden ser correctos (verdadero positivo, o verdadero negativo), o inconrrectos (falso positivo o falso negativo), donde: \n",
    "    1. verdadero positivo (VP), hace referencia a que se clasificó correctamente al patrón, donde perteneciendo éste a la clase, el resultado fue verdadero (1). \n",
    "    2. verdadero negativo (VN), al igual que en el caso anterior, los verdaderos negativos son aquellos patrones que no perteneciendo a la clase, el clasifidor los clasifica correctamente (0) \n",
    "    3. falsos positivos (FP), hace referencia a aquellos patrones que  perteneciendo a una determinada clasificación (1), se le clasifica como si éstos no perteneciesen (0). \n",
    "    4. falsos negativos (FN), serían los casos contrarios, i.e., los patrones que no pertenecen a la clasificación (0), se les clasifica como que  pertenecen (1).\n",
    "    \n",
    "La exactitud entonces, la mediremos como la relación siguiente (VP+FP)/(VP+VN+FP+FN). En otras palabras, acumularemos en un contador todos aquellos patrones que fueron correctamente clasificados y lo dividiremos entre el total de patrones evaluados. Evidentemente, aquel clasificador que no tenga ningún FP o FN, dará como resultado 1 (que es el caso deseable). En caso contrario dará un valor menor a 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (20 puntos extra) Exactitud RBFF múltiples clases > 0.9\n",
    "\n",
    "El estudiante obtendrá 20 puntos extra si la exactitud de la RBFNN con múltiples clases es superior a 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fecha de entrega: 2 de marzo de 2020 a las 12:00hrs. Toda tarea entregada tarde será penalizada con 10% (sobre la calificación obtenida) por cada periodo de 24 horas que se retrase su entrega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
